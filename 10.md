# Chapter 10: Page Frame Reclamation

* A running system will eventually use all available page frames for disk
  buffers, [struct dentry][dentry]s, [struct inode][inode]s, process pages,
  etc. etc.

* Linux needs to select old pages that can be freed and invalidated for new uses
  before physical memory becomes exhausted - this chapter focuses on how linux
  implements its 'page replacement policy' and how different types of pages are
  invalidated.

* The way linux selects pages is rather empirical and contains a mix of ideas
  moderated by user feedback and benchmarks.

* The page cache is a cache of all data that is read from disk to reduce the
  amount of disk I/O required. Strictly speaking this is not directly related to
  page frame reclamation, however the LRU lists and page cache are closely related.

* With the exception of the slab allocator, all pages in use by the system are
  stored on [LRU][lru] lists and linked together via [struct page][page]`->lru`
  so they can be easily scanned for replacement.

* The slab pages are not stored on the LRU lists as it's considerably harder to
  age a page based on the objects used by the slab.

* Process-mapped pages are not easily swappable because there is no easy way to
  map [struct page][page]s to PTEs except by searching every page table which is
  very expensive.

* If the page cache has a large number of process-mapped pages in it, process
  page tables will be walked and pages will be swapped out via
  [swap_out()][swap_out] until enough pages have been freed.

* Regardless, `swap_out()` will have trouble dealing with shared pages - if a
  page is shared a swap entry is allocated, the PTE is filled out with the
  necessary information to find the page in swap again and the reference count
  is decremented. Only when the count reaches 0 will it be freed - pages like
  this are considered to be in the 'swap cache'.

* Page replacement is performed via the the `kswapd` daemon.

## 10.1 Page Replacement Policy

* The page replacement policy is said to be an [LRU][lru]-based algorithm, but
  technically this isn't quite true because the lists are not strictly
  maintained in LRU order.

* The LRU in linux consists of two lists - [active_list][active_list] and
  [inactive_list][inactive_list]. The idea is for the `active_list` to contain
  the [working set][working-set] of all processes and the `inactive_list` to
  contain reclaim candidates.

* Since we store all reclaimable pages in two lists and pages belonging to any
  process may be reclaimed rather than just those belonging to a faulting
  process, the replacement policy is global.

* The lists resemble a simplified [LRU 2Q][lru-q2] (PDF link.) In 2Q, two lists
  are maintained - `Am` and `A1`. `A1` is a FIFO queue and if a page is
  referenced while on that queue they are placed in `Am` which is a normal
  LRU-managed list.

* The 2Q approach is roughly analogous to using [lru_cache_add()][lru_cache_add]
  to place pages on the `inactive_list` (`A1` in the analogy) and using
  [mark_page_accessed()][mark_page_accessed] to move them to the `active_list`
  (`Am` in the analogy.)

* The 2Q algorithm specifies how the size of the two lists have to be tuned but
  linux takes a simpler approach by using [refill_inactive()][refill_inactive]
  to move pages from the bottom of the `active_list` to the `inactive_list` to
  keep `active_list` about two-thirds the size of the total page
  cache. Diagrammatically:

```
                                      -------------------                 -------------------
                                      | activate_page() |                 | lru_cache_add() |
                                      -------------------                 -------------------
                                               |                                   |
                                               |                                   |
                                               v                                   v
                                 -----------------------------     -------------------------------
                                 | add_page_to_active_list() |  /->| add_page_to_inactive_list() |
                                 -----------------------------     -------------------------------
                                               |                |                  |
                                               |                                   |
                                               v                |                  v
                                        ---------------                    -----------------
                                        |  list head  |<------\ |          |   list head   |
    ---------------------               |-------------|       |            |---------------|
    | refill_inactive() |<-\   Page     |             |       | |          |               |
    ---------------------  | removed by | active_list |       |            | inactive_list |
              |               refill_   |             |       | |          |               |
              |            | inactive() |-------------|       |            |---------------|
              v            \ - - - - - -|  list tail  |       | |          |   list tail   |
   -----------------------              ---------------       |            -----------------
   | Move nr_pages pages |                                    | |                  |
   | from active_list to |                                    |                    |
   |    inactive_list    |                                    | |                  v
   -----------------------                                    |             ----------------
              |                                  active_list  | |           | page reclaim |
/------------>|                                   "rotates"   |             ----------------
|             v                                               | |
|   /---------------------\ no       /-------------------\    |
|  /   nr_pages != 0 &&    \------->/ Clear reference bit \---/ |
|  \ active_list has pages /        \     Was it set?     / yes
|   \---------------------/          \-------------------/      |
|             | yes                            | no
|             |                                V                |
|             v                          --------------
|     ------------------                 | nr_pages-- |         |
|     | nr_pages moved |                 --------------
|     |  Job complete  |                       |                |
|     ------------------                       |
|                                              v                |
|                               -------------------------------   page moves to
|                               | del_page_from_active_list() | | inactive_list
\-------------------------------|     Set referenced bit      |-/
                                | add_page_to_inactive_list() |
                                -------------------------------
```

* The list described for 2Q presumes `Am` is an LRU list, but the linux
  equivalent (`active_list`) is more like a [clock algorithm][clock-algorithm]
  where the 'handspread' is the size of the active list.

* When pages reach the bottom of the `active_list` the 'referenced' flag is
  checked. If it's set, the page is moved back to the top of the list and the
  next page is set. If it is cleared, it is moved to the
  `inactive_list`. Regardless of what is done, it is cleared.

* The 'move-to-front' heuristic means that the lists behave in an LRU-_like_
  manner, but there are just too many differences between the linux replacement
  policy and LRU to consider it a 'stack' algorithm.

* Other differences are that the list priority is not order because that would
  require list updates with every reference and the lists are all but ignored
  when paging out from processes because this is decided base on the location of
  the pages in the virtual address space of the process rather than their
  location within the page lists.

* To summarise, the algorithm exhibits LRU-_like_ behaviour and has been shown
  by benchmarks to perform well in practice.

* There are two cases where the algorithm performs badly:

1. When candidates for reclamation are mostly anonymous pages - in this case
   linux will keep on examining a large number of pages before linearly scanning
   process page tables searching for the pages to reclaim. Thankfully this is
   rare.

2. When a single process has a large number of file-backed resident pages in the
   `inactive_list` that are being written to frequently. In this case processes
   and `kswapd` may go into a loop of constantly 'laundering' these pages and
   putting them at the top of the `inactive_list` without freeing anything - in
   this case few pages are moved from the `active_list` to the `inactive_list`.

## 10.2 Page Cache

* The page cache is a set of  data structures that contain pages that are backed
  by ordinary files, block devices, or swap. There are basically 4 types of page
  that exist in the cache:

1. Pages that were 'faulted in' as a result of reading a memory-mapped file.

2. Pages read from a block device or filesystem - these are special pages known
   as 'buffer pages'. The number of blocks that may fit there depends on the
   size of the block and the page size of the architecture.

3. Anonymous pages that live in the 'swap cache', a special part of the page
   cache, when slots are allocated in the backing storage for
   page-out. Discussed further in chapter 11.

4. Pages belonging to shared memory regions are treated similarly to anonymous
   pages - the only different is that shared pages are added to the swap cache
   and space is reserved in backing storage immediately after the first write to
   the page.

* The main reason for the existence of the page cache is to eliminate
  unnecessary disk reads. Pages read from disk are stored in a _page hash_
  table, which is hashed on the [struct address_space][address_space] and the
  offset. The hash is always searched before resorting to a disk read.

* Let's take a look at the page cache API:

1. [add_to_page_cache()][add_to_page_cache] - Adds a page to the LRU via
   [lru_cache_add()][lru_cache_add] in addition to adding it to the inode queue
   and page hash tables.

2. [add_to_page_cache_unique()][add_to_page_cache_unique] - Same as
   `add_to_page_cache()` except it checks to make sure the page isn't already
   there. Required when the caller doesn't hold the
   [pagecache_lock][pagecache_lock].

3. [remove_inode_page()][remove_inode_page] - Removes a page from the inode and
   hash queues via
   [remove_page_from_inode_queue()][remove_page_from_inode_queue] and
   [remove_page_from_hash_queue()][remove_page_from_hash_queue] which
   effectively removes the page from the page cache altogether.

4. [page_cache_alloc()][page_cache_alloc] - Wrapper around
   [alloc_pages()][alloc_pages] that uses the
   [struct address_space][address_space]'s `gfp_mask` field as the GFP mask.

5. [page_cache_get()][page_cache_get] - Increment [struct page][page]`->count`,
   i.e. the page's reference count. Wrapper around [get_page()][get_page].

6. [page_cache_read()][page_cache_read] - Adds a page corresponding to a
   specified `offset` and `file` to the page cache if not already there. If
   necessary, page will be read from disk via
   [struct address_space_operations][address_space_operations]

7. [page_cache_release()][page_cache_release] - Alias for
   [__free_page()][__free_page] - reference count is decremented and if it drops
   to 0, the page is freed.

### 10.2.1 Page Cache Hash Table

* Pages in the page cache need to be located quickly. Pages are inserted into
  the [page_hash_table][page_hash_table] hash table and
  [struct page][page]`->next_hash` and `->pprev_hash` are used to handle
  collisions.

* The table is declared as follows in `mm/filemap.c`:

```c
atomic_t page_cache_size = ATOMIC_INIT(0);
unsigned int page_hash_bits;
struct page **page_hash_table;
```

* The table is allocated during system initialisation via
  [page_cache_init()][page_cache_init]:

```c
void __init page_cache_init(unsigned long mempages)
{
        unsigned long htable_size, order;

        htable_size = mempages;
        htable_size *= sizeof(struct page *);
        for(order = 0; (PAGE_SIZE << order) < htable_size; order++)
                ;

        do {
                unsigned long tmp = (PAGE_SIZE << order) / sizeof(struct page *);

                page_hash_bits = 0;
                while((tmp >>= 1UL) != 0UL)
                        page_hash_bits++;

                page_hash_table = (struct page **)
                        __get_free_pages(GFP_ATOMIC, order);
        } while(page_hash_table == NULL && --order > 0);

        printk("Page-cache hash table entries: %d (order: %ld, %ld bytes)\n",
               (1 << page_hash_bits), order, (PAGE_SIZE << order));
        if (!page_hash_table)
                panic("Failed to allocate page hash table\n");
        memset((void *)page_hash_table, 0, PAGE_HASH_SIZE * sizeof(struct page *));
}
```

* This takes `mempages`, the number of physical pages in the system, as a
  parameter and uses it to determine the hash table's size, `htable_size`:

```c
htable_size = mempages;
htable_size *= sizeof(struct page *);
```

* This is sufficient to hold pointers to every [struct page][page] in the
  system.

* The system then determines an `order` such that `PAGE_SIZE * 2^order <
  htable_size` (roughly equivalent to `order = floor(lg((htable_size * 2) -
  1))`):

```c
for(order = 0; (PAGE_SIZE << order) < htable_size; order++)
        ;
```

* The pages are allocated via [__get_free_pages()][__get_free_pages] if
  possible, trying lower orders if not and panicking if unable to allocate
  anything.

* Next the function determines `page_hash_bits`, the number of bits to use in
  the hashing function [_page_hashfn()][_page_hashfn]:

```c
unsigned long tmp = (PAGE_SIZE << order) / sizeof(struct page *);

page_hash_bits = 0;
while((tmp >>= 1UL) != 0UL)
        page_hash_bits++;
```

* This is equivalent to `page_hash_bits = lg(PAGE_SIZE*2^order/sizeof(struct
  page *))`, which renders the table a power-of-two hash table, negating the
  need to use a modulus (a common choice for hashing functions.)

* Finally, the page table is zeroed.

### 10.2.2 inode Queue

* The 'inode queue' is part of the [struct address_space][address_space]
  introduced in 4.4.2.

* `struct address_space` contains 3 lists associated with the inode -
  `clean_pages`, `dirty_pages`, and `locked_pages` - dirty pages are ones that
  have been changed since the last sync to disk and locked pages are
  unsurprisingly ones that are locked :)

* These three lists in combination are considered to be the inode queue for a
  given mapping, and the multi-purpose [struct page][page]`->list` field is used
  to link pages on it.

* Pages are added to the inode queue via
  [add_page_to_inode_queue()][add_page_to_inode_queue] and removed via
  [remove_page_from_inode_queue()][remove_page_from_inode_queue].

### 10.2.3 Adding Pages to the Page Cache

* Pages read from a file or block device are generally added to the page cache
  to avoid further disk I/O. Most filesystems uses the high-level
  [generic_file_read()][generic_file_read] as their `file_operations->read()`.

* `generic_file_read()` does the following:

1. Performs a few sanity checks then, if direct I/O, hands over to
  [generic_file_direct_IO()][generic_file_direct_IO], otherwise calls
  [do_generic_file_read()][do_generic_file_read] to do the heavy lifting (we
  don't consider direct I/O here.)

2. Searches the page cache by calling [__find_page_nolock()][__find_page_nolock]
   with the [pagecache_lock][pagecache_lock] held to see if the page already
   exists in it.

3. If the page does not already exist, a new page is allocated via
   [page_cache_alloc()][page_cache_alloc] and added to the page cache via
   [__add_to_page_cache()][__add_to_page_cache].

4. After a page frame is present in the page cache,
   [generic_file_readahead()][generic_file_readahead] is called which uses
   [page_cache_read()][page_cache_read] to read pages from disk via
   `mapping->a_ops->readpage()` where `mapping` is the
   [struct address_space][address_space] managing the file.

* Anonymous pages are added to the swap cache when they are unmapped from a
  process (see 11.4) and have no `struct address_space` acting as a mapping, or
  any offset within a file, which leaves nothing to hash them into the page
  cache with.

* These anonymous pages will still exist on the LRU lists, however. Once in the
  swap cache, the only real difference between anonymous pages and file-backed
  pages is that anonymous pages will use [swapper_space][swapper_space] as their
  `struct address_space`.

* Shared memory pages are added when:

1. [shmem_getpage()][shmem_getpage] is called when a page has be either fetched
   from swap or allocated because it is the first reference.

2. The swapout code calls [shmem_unuse()][shmem_unuse] when a swap area is being
   deactivated and a page backed by swap space is found that does not appear to
   belong to any process. In this case the inodes related to shared memory are
   exhaustively searched until the correct page is found.

* In both cases the page is added with [add_to_page_cache()][add_to_page_cache].


[dentry]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/dcache.h#L67
[inode]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/fs.h#L438
[lru]:https://en.wikipedia.org/wiki/Cache_algorithms#LRU
[page]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/mm.h#L154
[swap_out]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/vmscan.c#L269

[active_list]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/page_alloc.c#L29
[inactive_list]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/page_alloc.c#L28
[working-set]:https://en.wikipedia.org/wiki/Working_set
[lru-2q]:http://www.vldb.org/conf/1994/P439.PDF
[lru_cache_add]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/swap.c#L58
[mark_page_accessed]: https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L1332
[refill_inactive]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/vmscan.c#L533
[clock-algorithm]:https://en.wikipedia.org/wiki/Page_replacement_algorithm#Clock

[address_space]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/fs.h#L406
[add_to_page_cache]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L667
[add_to_page_cache_unique]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L675
[pagecache_lock]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/swap.h#L94
[remove_inode_page]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L130
[remove_page_from_inode_queue]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L94
[remove_page_from_hash_queue]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L107
[page_cache_alloc]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/pagemap.h#L34
[alloc_pages]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/mm.h#L439
[page_cache_get]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/pagemap.h#L31
[get_page]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/mm.h#L196
[page_cache_read]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L702
[address_space_operations]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/fs.h#L385
[page_cache_release]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/pagemap.h#L32
[__free_page]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/mm.h#L471
[page_hash_table]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L47
[page_cache_init]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L3318
[__get_free_pages]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/page_alloc.c#L428
[_page_hashfn]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/pagemap.h#L62
[add_page_to_inode_queue]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L85
[generic_file_read]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L1695
[generic_file_direct_IO]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L1581
[do_generic_file_read]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L1349
[__find_page_nolock]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L443
[__add_to_page_cache]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L653
[generic_file_readahead]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/filemap.c#L1222
[swapper_space]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/swap_state.c?v=linux-2.4.22#L39
[shmem_getpage]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/mm/shmem.c#L583
[shmem_unuse]:https://github.com/lorenzo-stoakes/linux-historical/blob/v2.4.22/include/linux/swap.h#L213
