# Chapter 2: Describing Physical Memory

* NUMA - Non-Uniform Memory Access. Memory arranged into banks, incurring a
  different cost for access depending on their distance from the processor.

* Each of these banks is called a 'node', represented by
  [struct pglist_data][pglist_data] _even if the arch is UMA_.

* The struct is always referenced by a typedef, `pg_data_t`.

* Every node is kept on a `NULL` terminated linked list, `pgdat_list`, and
  linked by `pg_data_t->node_next`.

* On UMA arches, only one `pg_data_t` structure called `contig_page_data` is
  used.

* Each node is divided into blocks called zones, which represent ranges of
  memory, described by [struct zone_struct][zone_struct], typedef-d to `zone_t`,
  one of `ZONE_DMA`, `ZONE_NORMAL` or `ZONE_HIGHMEM`.

* `ZONE_DMA` is kept within lower physical memory ranges that certain ISA
  devices need.

* `ZONE_NORMAL` memory is directly mapped into the upper region of the linear
  address space.

* `ZONE_HIGHMEM` is what's is left.

* In a 32-bit kernel the mappings are:

```
ZONE_DMA - First 16MiB of memory
ZONE_NORMAL - 16MiB - 896MiB
ZONE_HIGHMEM - 896 MiB - End
```

* Many kernel operations can _only_ take place in `ZONE_NORMAL`. So this is the
  most performance critical zone.

* Memory is divided into fixed-size chunks called _page frames_, represented by
  [struct page][page], and all of these are kept in a global `mem_map` array,
  usually stored at the beginning of `ZONE_NORMAL` or just after the area
  reserved for the loaded kernel image in low memory machines.

* Because the amount of memory directly accessible by the kernel (`ZONE_NORMAL`)
  is limited in size, Linux has the concept of _high memory_.

## 2.1 Nodes

* Each node is described by a `pg_data_t`, which is a `typedef` for
[struct pglist_data][pglist_data]:

```c
typedef struct pglist_data {
	zone_t node_zones[MAX_NR_ZONES];
	zonelist_t node_zonelists[GFP_ZONEMASK+1];
	int nr_zones;
	struct page *node_mem_map;
	unsigned long *valid_addr_bitmap;
	struct bootmem_data *bdata;
	unsigned long node_start_paddr;
	unsigned long node_start_mapnr;
	unsigned long node_size;
	int node_id;
	struct pglist_data *node_next;
 } pg_data_t;
```

### Fields

* `node_zones` - `ZONE_HIGHMEM`, `ZONE_NORMAL`, `ZONE_DMA`.

* `node_zonelists` - Order of zones allocations are preferred
  from. [build_zonelists()][build_zonelists] in `mm/page_alloc.c` sets up the
  order, called by [free_area_init_core()][free_area_init_core]. A failed
  allocation in `ZONE_HIGHMEM` may fall back to `ZONE_NORMAL` or back to
  `ZONE_DMA`.

* `nr_zones` - Number of zones in this node, between 1 and 3 (not all nodes will
  have all zones.)

* `node_mem_map` - First page of the [struct page][page] array that represents
  each physical frame in the node. Will be placed somewhere in the `mem_map` array.

* `valid_addr_bitmap` - Used by sparc/sparc64.

* `bdata` - Boot memory information only.

* `node_start_paddr` - Starting physical address of the node.

* `node_start_mapnr` - Page offset within global `mem_map`. Calculated in
  [free_area_init_core()][free_area_init_core] by determining number of pages
  between `mem_map` and local `mem_map` for this node called `lmem_map`.

* `node_size` - Total number of pages in this zone.

* `node_id` - Node ID (NID) of node, starting at 0.

* `node_next` - Pointer to next node, `NULL` terminated list.

* Nodes are maintained on a list called `pgdat_list`. Nodes are placed on the
  list as they are initialised by the [init_bootmem_core()][init_bootmem_core]
  function. They can be iterated over using [for_each_pgdat][for_each_pgdat], e.g.:

```c
pg_data_t *pgdat;

for_each_pgdat(pgdat)
	pr_debug("node %d: size=%d", pgdat->node_id, pgdat->node_size);
```

## 2.2 Zones

* Each zone is described by a [struct zone_struct][zone_struct]:

```c
typedef struct zone_struct {
	/*
	 * Commonly accessed fields:
	 */
	spinlock_t              lock;
	unsigned long           free_pages;
	unsigned long           pages_min, pages_low, pages_high;
	int                     need_balance;

	/*
	 * free areas of different sizes
	 */
	free_area_t             free_area[MAX_ORDER];

	/*
	 * wait_table           -- the array holding the hash table
	 * wait_table_size      -- the size of the hash table array
	 * wait_table_shift     -- wait_table_size
	 *                              == BITS_PER_LONG (1 << wait_table_bits)
	 *
	 * The purpose of all these is to keep track of the people
	 * waiting for a page to become available and make them
	 * runnable again when possible. The trouble is that this
	 * consumes a lot of space, especially when so few things
	 * wait on pages at a given time. So instead of using
	 * per-page waitqueues, we use a waitqueue hash table.
	 *
	 * The bucket discipline is to sleep on the same queue when
	 * colliding and wake all in that wait queue when removing.
	 * When something wakes, it must check to be sure its page is
	 * truly available, a la thundering herd. The cost of a
	 * collision is great, but given the expected load of the
	 * table, they should be so rare as to be outweighed by the
	 * benefits from the saved space.
	 *
	 * __wait_on_page() and unlock_page() in mm/filemap.c, are the
	 * primary users of these fields, and in mm/page_alloc.c
	 * free_area_init_core() performs the initialization of them.
	 */
	wait_queue_head_t       * wait_table;
	unsigned long           wait_table_size;
	unsigned long           wait_table_shift;

	/*
	 * Discontig memory support fields.
	 */
	struct pglist_data      *zone_pgdat;
	struct page             *zone_mem_map;
	unsigned long           zone_start_paddr;
	unsigned long           zone_start_mapnr;

	/*
	 * rarely used fields:
	 */
	char                    *name;
	unsigned long           size;
 } zone_t;
```

### Fields

* `lock` - Spinlock protects the zone from concurrent accesses.

* `free_pages` - Total number of free pages in the zone.

* `pages_min`, `pages_low`, `pages_high` - Watermarks - If `free_pages <
  pages_low`, `kswapd` is woken up and swaps pages out asynchronously. If the
  page consumption doesn't slow down fast enough from this, `kswapd` switches
  into a mode where pages are freed synchronously in order to return the system
  to health (see 2.2.1.)

* `need_balance` - This indicates to `kswapd` that it needs to balance the zone,
  i.e. `free_pages` has hit one of the watermarks.

* `free_area` - Free area bitmaps used by the buddy allocator.

* `wait_table` - Hash table of wait queues of processes waiting on a page to be
  freed. This is meaningful to [wait_on_page()][wait_on_page] and
  [unlock_page()][unlock_page]. A 'wait table' is used because, if processes all
  waited on a single queue, there'd be a big race between processes for pages
  which are locked on wake up (known as a 'thundering herd'.)

* `wait_table_size` - Number of queues in the hash table (power of 2.)

* `wait_table_shift` - Number of bits in a long - binary logarithm of `wait_table_size`.

* `zone_pgdat` - Points to the parent `pg_data_t`.

* `zone_mem_map` - First page in a global `mem_map` that this zone refers to.

* `zone_start_paddr` - Starting physical address of the zone.

* `zone_start_mapnr` - Page offset within global `mem_map`.

* `name` - String name of the zone - `"DMA"`, `"Normal"` or `"HighMem"`.

* `size` - Size of zone in pages.

### 2.2.1 Zone Watermarks

* When system memory is low, the pageout daemon `kswapd` is woken up to free pages.

* If memory pressure is high `kswapd` will free memory synchronously - the
  _direct-reclaim_ path.

* Each zone has 3 watermarks - `pages_min`, `pages_low` and `pages_high`.

* `pages_min` is determined by [free_area_init_core()][free_area_init_core]
  during memory initialisation and is based on a ratio related to the size of
  the zone in pages, initially as `zone_size_in_pages/128`, its value varies
  from 20 to 255 pages (80KiB - 1MiB on x86.) When this is reached it's time to
  get serious - memory is _synchronously_ freed.

* `pages_low = 2*pages_min` by default. When this amount of free memory is
  reached, `kswapd` is woken up by the 'buddy allocator' in order to start
  freeing pages.

* `pages_high = 3*pages_min` by default. After `kswapd` has been woken to start
  freeing pages, the zone won't be considered to be 'balanced' until
  `pages_high` pages are free again.

### 2.2.2 Calculating the Sizes of Zones

* The size of each zone is calculated during [setup_memory()][setup_memory].

* _PFN_ - Page Frame Number - is an offset in pages within the physical memory
  map.

* The PFN variables mentioned below are kept in [mm/bootmem.c][bootmem.c].

* `min_low_pfn` - the first PFN usable by the system - is located in the first
  page after the global variable `_end` (this variable represents the end of the
  loaded kernel image.)

* `max_pfn` - the last page frame in the system - is determined in a very
  architecture-specific fashion. In x86 the function
  [find_max_pfn()][find_max_pfn] reads through the whole [e820][e820] map (a
  table provided by BIOS describing what physical memory is available, reserved,
  or non-existent) in order to find the highest page frame.

* `max_low_pfn` is calculated on x86 with
  [find_max_low_pfn()][find_max_low_pfn], and marks the end of
  `ZONE_NORMAL`. This is the maximum page of physical memory directly accessible
  by the kernel, and is related to the kernel/username split in the linear
  address space determined by [PAGE_OFFSET][__PAGE_OFFSET]. In low memory
  machines `max_pfn = max_low_pfn`.

* Once we have these values we can determine the start and end of high memory
  (`highstart_pfn` and `highend_pfn`) [very simply][highstart_pfn_ASSIGN]:

```c
	highstart_pfn = highend_pfn = max_pfn;
	if (max_pfn > max_low_pfn) {
		highstart_pfn = max_low_pfn;
	}
```

* These values are used later to initialise the high memory pages for the
  physical page allocator (see section 5.6)

### 2.2.3 Zone Wait Queue Table

* When I/O is being performed on a page such as during page-in or page-out, I/O
  is locked to avoid exposing inconsistent data.

* Processes that want to use a page undergoing I/O have to join a wait queue
  before it can be accessed by calling [wait_on_page()][wait_on_page].

* When the I/O is complete the page will be unlocked with
  [UnlockPage()][UnlockPage] (`#define`'d as [unlock_page()][unlock_page]) and
  any processes waiting on the queue will be woken up.

* If every page had a wait queue it would use a lot of memory, so instead the
  wait queue is stored within the relevant [zone_t][zone_struct].

* The process of sleeping on a locked page can be described as follows:

1. Process A wants to lock page.

2. The kernel calls [__wait_on_page()][__wait_on_page]...

3. ...which calls [page_waitqueue()][page_waitqueue] to get the page's wait
   queue...

4. ...which calls [page_zone()][page_zone] to obtain the page's zone's
   [zone_t][zone_struct] structure using the page's `flags` field shifted by
   `ZONE_SHIFT`...

5. ...[page_waitqueue()][page_waitqueue] will then hash the page address to read
   into the `zone`'s `wait_table` field and retrieve the appropriate
   [wait_queue_head_t][__wait_queue_head].

6. This is used by [add_wait_queue()][add_wait_queue] to add the process to the
wait queue, at which point it goes beddy byes!

* As described above, a hash table is used rather than simply keeping a single
  wait list. This is done because a single list could result in a serious
  [thundering herd][thundering herd] problem.

* In the event of a hash collision processes might still get woken up
  unnecessarily, but collisions aren't expected that often.

* The `wait_table` field is allocated during
  [free_area_init_core()][free_area_init_core], its size is calculated by
  [wait_table_size()][wait_table_size] and stored in the `wait_table_size`
  field, with a maximum size of 4,096 wait queues.

* For smaller tables, the size of the table is the minimum power of 2 required
  to store `NoPages / PAGES_PER_WAITQUEUE` (`NoPages` is the number of pages in
  the zone and `PAGES_PER_WAITQUEUE` is defined as 256.) This means the size of
  the table is `floor(log2(2 * NoPages/PAGE_PER_WAITQUEUE - 1))`.

[pglist_data]:http://fxr.watson.org/fxr/source/include/linux/mmzone.h?v=linux-2.4.22#L129
[build_zonelists]:http://fxr.watson.org/fxr/source/mm/page_alloc.c?v=linux-2.4.22#L589
[free_area_init_core]:http://fxr.watson.org/fxr/source/mm/page_alloc.c?v=linux-2.4.22#L684
[page]:http://fxr.watson.org/fxr/source/include/linux/mm.h?v=linux-2.4.22#L154
[for_each_pgdat]:http://fxr.watson.org/fxr/source/include/linux/mmzone.h?v=linux-2.4.22#L172
[zone_struct]:http://fxr.watson.org/fxr/source/include/linux/mmzone.h?v=linux-2.4.22#L37
[wait_on_page]:http://fxr.watson.org/fxr/source/include/linux/pagemap.h?v=linux-2.4.22#L94
[unlock_page]:http://fxr.watson.org/fxr/source/mm/filemap.c?v=linux-2.4.22#L874
[free_area_init_core]:http://fxr.watson.org/fxr/source/mm/page_alloc.c?v=linux-2.4.22#L684
[setup_memory]:http://fxr.watson.org/fxr/source/arch/i386/kernel/setup.c?v=linux-2.4.22#L991
[find_max_pfn]:http://fxr.watson.org/fxr/source/arch/i386/kernel/setup.c?v=linux-2.4.22#L873
[e820]:https://en.wikipedia.org/wiki/E820
[find_max_low_pfn]:http://fxr.watson.org/fxr/source/arch/i386/kernel/setup.c?v=linux-2.4.22#L895
[__PAGE_OFFSET]:http://fxr.watson.org/fxr/source/include/asm-i386/page.h?v=linux-2.4.22#L81
[bootmem.c]:http://fxr.watson.org/fxr/source/mm/bootmem.c?v=linux-2.4.22
[highstart_pfn_ASSIGN]:http://fxr.watson.org/fxr/source/arch/i386/kernel/setup.c?v=linux-2.4.22#L1006
[wait_on_page]:http://fxr.watson.org/fxr/source/include/linux/pagemap.h?v=linux-2.4.22#L94
[UnlockPage]:http://fxr.watson.org/fxr/source/include/linux/mm.h?v=linux-2.4.22#L309
[unlock_page]:http://fxr.watson.org/fxr/source/mm/filemap.c?v=linux-2.4.22#L874
[__wait_on_page]:http://fxr.watson.org/fxr/source/mm/filemap.c?v=linux-2.4.22#L849
[page_waitqueue]:http://fxr.watson.org/fxr/source/mm/filemap.c?v=linux-2.4.22#L783
[thundering herd]:https://en.wikipedia.org/wiki/Thundering_herd_problem
[page_zone]:http://fxr.watson.org/fxr/source/include/linux/mm.h?v=linux-2.4.22#L339
[__wait_queue_head]:http://fxr.watson.org/fxr/source/include/linux/wait.h?v=linux-2.4.22#L77
[add_wait_queue]:http://fxr.watson.org/fxr/source/kernel/fork.c?v=linux-2.4.22#L42
[wait_table_size]:http://fxr.watson.org/fxr/source/mm/page_alloc.c?v=linux-2.4.22#L647
